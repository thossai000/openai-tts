{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thossai000/openai-tts/blob/main/OpenAI_TTS_Gradio_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uv --quiet --progress-bar=off\n",
        "!uv pip install --system --quiet gradio requests pydub"
      ],
      "metadata": {
        "id": "tbNFFWPF63xG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import gradio as gr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "eqe0CEHh3USO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**requests** is a powerful library for making HTTP requests.\n",
        "\n",
        "**gradio** is an easy way to build web UIs in Python.\n",
        "\n",
        "**pydub** helps with audio manipulation (for example, converting response bytes if they come in MP3 format and Gradio expects WAV).\n",
        "\n",
        "**io.BytesIO** can help us handle audio as in-memory bytes."
      ],
      "metadata": {
        "id": "35QuvCOCkgdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "# We need credentials to authenticate requests to the TTS endpoint. This is our openAI key we generated in our account"
      ],
      "metadata": {
        "id": "uz0_uRsBkKOi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store your key in a secret if you’re using a public environment like Hugging Face Spaces."
      ],
      "metadata": {
        "id": "eBkajcQMkdCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''We’ll create a Python function that takes in text, chooses a TTS model (e.g., tts-1 or tts-1-hd),\n",
        "and returns raw audio bytes (MP3 or WAV).'''\n",
        "def call_openai_tts(text, model=\"tts-1\"):\n",
        "    \"\"\"\n",
        "    Call the hypothetical OpenAI TTS endpoint with the given text,\n",
        "    returning raw audio content (e.g., MP3 bytes).\n",
        "    \"\"\"\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in environment.\")\n",
        "\n",
        "    # Hypothetical endpoint (this is not an official endpoint)\n",
        "    url = f\"https://api.openai.com/v1/audio/generations?model={model}\"\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {openai_api_key}\",\n",
        "    }\n",
        "\n",
        "    # The exact payload structure depends on how OpenAI TTS expects data\n",
        "    # We'll assume a JSON with 'text' param\n",
        "    payload = {\n",
        "        \"text\": text\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        raise RuntimeError(f\"TTS request failed: {response.status_code} {response.text}\")\n",
        "\n",
        "    # For demonstration, assume 'audio_content' in the response holds the MP3 audio in base64 or raw bytes\n",
        "    # If it’s returned as raw bytes, we can directly use response.content\n",
        "    # If it’s base64, we’d decode it\n",
        "    # Let's pretend the response is direct binary MP3 data:\n",
        "    audio_bytes = response.content\n",
        "\n",
        "    return audio_bytes"
      ],
      "metadata": {
        "id": "akDXEc8NoVwk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we wrote a Function to Call the TTS Endpoint,\n",
        "\n",
        "Next we setup a Gradio UI\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_4TIfxD0qHId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def generate_speech(text, model_choice, voice_choice=\"alloy\"):\n",
        "    \"\"\"\n",
        "    Generate speech from text using OpenAI's TTS API\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to convert to speech\n",
        "        model_choice (str): Model to use (tts-1 or tts-1-hd)\n",
        "        voice_choice (str): Voice to use (default: alloy)\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the generated audio file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Call OpenAI's TTS API using the official client library\n",
        "        response = client.audio.speech.create(\n",
        "            model=model_choice,\n",
        "            voice=voice_choice,\n",
        "            input=text\n",
        "        )\n",
        "\n",
        "        # Get the speech data\n",
        "        speech_data = response.read()\n",
        "\n",
        "        # Convert MP3 bytes to WAV for Gradio\n",
        "        audio_segment = AudioSegment.from_file(BytesIO(speech_data), format=\"mp3\")\n",
        "\n",
        "        # Save the WAV file temporarily\n",
        "        output_file = \"output.wav\"\n",
        "        audio_segment.export(output_file, format=\"wav\")\n",
        "\n",
        "        return output_file\n",
        "\n",
        "    except Exception as e:\n",
        "        raise gr.Error(f\"Failed to generate speech: {str(e)}\")\n",
        "\n",
        "# Define available voices and models\n",
        "AVAILABLE_VOICES = [\"alloy\", \"echo\", \"fable\", \"onyx\", \"nova\", \"shimmer\"]\n",
        "AVAILABLE_MODELS = [\"tts-1\", \"tts-1-hd\"]\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# OpenAI Text-to-Speech Demo\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"Enter text to synthesize\",\n",
        "                value=\"Hello! This is a test of OpenAI's text-to-speech technology.\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                model_input = gr.Radio(\n",
        "                    choices=AVAILABLE_MODELS,\n",
        "                    value=\"tts-1\",\n",
        "                    label=\"TTS Model\"\n",
        "                )\n",
        "                voice_input = gr.Radio(\n",
        "                    choices=AVAILABLE_VOICES,\n",
        "                    value=\"alloy\",\n",
        "                    label=\"Voice\"\n",
        "                )\n",
        "\n",
        "            generate_button = gr.Button(\"Generate Speech\")\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_output = gr.Audio(\n",
        "                label=\"Generated Speech\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "\n",
        "    # Add some helpful information\n",
        "    gr.Markdown(\"\"\"\n",
        "    ### Model Information\n",
        "    - **tts-1**: Standard quality model, faster generation\n",
        "    - **tts-1-hd**: Higher quality model, slightly slower generation\n",
        "\n",
        "    ### Voice Descriptions\n",
        "    - **alloy**: Versatile, balanced voice\n",
        "    - **echo**: Warm, natural voice\n",
        "    - **fable**: Expressive, youthful voice\n",
        "    - **onyx**: Deep, authoritative voice\n",
        "    - **nova**: Energetic, professional voice\n",
        "    - **shimmer**: Clear, gentle voice\n",
        "    \"\"\")\n",
        "\n",
        "    # Set up the event handler\n",
        "    generate_button.click(\n",
        "        fn=generate_speech,\n",
        "        inputs=[text_input, model_input, voice_input],\n",
        "        outputs=audio_output\n",
        "    )\n",
        "\n",
        "# Launch the demo\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "p4uBeROirD6i",
        "outputId": "e11d5221-a440-4238-82f3-a6b5b0358309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://bc98d2cf2adb1b2bcf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bc98d2cf2adb1b2bcf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}